x = read.csv('MLProjectData.csv', header = TRUE)
test = read.csv('testData.csv', header= TRUE)



######dealing with data#################
###dummy variables for categorical#####
train = dummy_cols(x, select_columns = c("cat1","cat2"), remove_first_dummy = FALSE,
                   remove_most_frequent_dummy = FALSE)

#drop old dummys
train$cat1 = NULL
train$cat2 = NULL
cols <- sapply(train, is.logical)
train[,cols] <- lapply(train[,cols], as.numeric)





####make logical variables binary#####
ix <- 62:86 
train[ix] <- lapply(train[ix], as.numeric) 
#x = read.csv('MLProjectData.csv', header = TRUE)
head(train)
####75/25 split into train and validation####
#set.seed(123)
# = sample(c(T,F),size=1:n, replace=T,prob=c(0.8,0.2))
row_count <- nrow(train)
shuffled_rows <- sample(row_count)
train <- train[head(shuffled_rows,floor(row_count*0.75)),]
test <- train[tail(shuffled_rows,floor(row_count*0.25)),]

####BASELINE- SLR####
model = lm(target~., data = train)
predictions = predict(model,train)
MAE_base= sum(abs(train$target-predictions)/length(train$target))

predictions2 = predict(model,valid)
MA_base2= sum(abs(train$valid-predictions)/length(valid$target))


#######Random Forest###########3
library('randomForest')

####run random forest on training data against all variables####
rf = randomForest(target ~ ., data=train, mtry = 5, ntree=500)
MAE = sum(abs(train$target-rf$predicted))/length(train$target)


#rf$err.mse
(rf$mse)



#' Let's try to get a sense of how many trees are necessary to get a good 
#' performance on the test data. (Tuning the hyperparameter ntrees.)
######how many trees#####
accuracy=vector()
ntrees=seq(1,70,20)
i=1
for(n in ntrees){
  rf = randomForest(target ~ ., data=train, ntree=n, type='response')
  test_pred =  predict(rf,valid,type='response')
  accuracy[i] =  sum(test_pred!=valid$target)/nrow(valid)
  i=i+1
}
plot(ntrees, accuracy)

#' Clear that we don't need that many trees here. Effect seems to level off
#' after 20-100 trees. Let's look over that range.
######how many trees######
accuracy=vector()
ntrees=seq(1,100,2)
i=1
for(n in ntrees){
  rf = randomForest(target ~ ., data=train, ntree=n, type='response')
  test_pred =  predict(rf,valid,type='response')
  accuracy[i] =  sum(test_pred!=valid$target)/nrow(valid)
  i=i+1
}

plot(ntrees, accuracy)

#' We could also play around with the other parameters, like mtry:

accuracy=vector()
mtry=seq(1,10)
i=1
for(m in mtry){
  rf = randomForest(target ~ ., data=train,mtry=m, ntree=500, type='response')
  test_pred =  predict(rf,valid,type='response')
  accuracy[i] =  sum(test_pred!=valid$target)/nrow(valid)
  i=i+1
}

plot(mtry, accuracy)

#' Can get some good information about variable importance using the importance=T option
rf = randomForest(target ~ ., data=train,importance = T,ntree=100)
#' Tells us which variables are important in prediction of each digit
importance(rf)


###############GRADIENT BOOSTING###############
 # first prepare the data

library('Matrix')

###code below does categoricals (everything from the beginning)####
sparse_train = sparse.model.matrix(target ~ . -target, data=train)
sparse_valid = sparse.model.matrix(target ~ . -target, data=valid)
#label = our target

library(xgboost)
library(readr)
library(stringr)
library(caret)
library(car)
# tune and run the model
#mat =as.matrix(train)
#mat_v = as.matrix(valid)
dtrain <- xgb.DMatrix(data = sparse_train[1:nrow(train), ], label = train$target)
dvalid <- xgb.DMatrix(data = sparse_valid[1:nrow(valid), ], label = valid$target)
#test_mat = as.matrix(test)
#dtest <- xgb.DMatrix(data = test[(nrow(test)+1):nrow(test)])
xgb <- xgboost(data = dtrain,
               objective = "reg:linear",
                   eta = 0.05,
                   max_depth = 15,
                   gamma = 0,
                   nround=100,
                   subsample = 0.75,
                   colsample_bytree = 0.75,
                   nthread = 3,
                    eval_metric = 'rmse',
                   verbose =0)
ptrain = predict(xgb, dtrain)
pvalid = predict(xgb, dvalid)
table(ptrain,train$target)
XGBmrt = sum(abs(train$target-ptrain))/length(train$target)
XGBmrv = sum(abs(valid$target-pvalid))/length(valid$target)
cat('XGB MAE:', XGBmrt)
cat('XGB MAE:', XGBmrv)



###########neural networks################
#PACKAGE = NEURALNET
library(neuralnet)
attach(train)
library(tidyverse)
#For the purposes of our tutorial, we’ll go with range standardization. This
#will allow us to practice writing a function as well! This normalize function applies to variable vectors,
#and we’ll need to apply it to every column of our data frame - including the target!
scaleRange = function(x) {
  + return((x-min(x))/(max(x)-min(x)))
}

train_nn = train

train_norm = scaleRange(train)
valid_norm=scaleRange(valid)

#Let’s get started with something simple, a neural network with only one hidden unit, and see how it
# performs compared to the linear regression. You can then plot the resulting network structure with the
#associated weights using the plot() command.n <- names(train_)

library(neuralnet)
n <- names(train_norm)
f <- as.formula(paste("target ~", paste(n[!n %in% "target"], collapse = " + ")))
nnet1 = neuralnet(f, data=train_norm, hidden=2)
#plot(nnet1)
#To predict the strength variable on the validation data, we’ll need to use the compute() function of the
#neuralnet package. This function computes not only the final model output (in the $net.result component),
#but also the computed value at each neuron (in the $neurons component). We’ll only want to retrieve the
#former. We’ll use the predicted values to calculate a validation R
# 2 as well as a MAPE.

results1 = neuralnet::compute(nnet1, valid_norm[,1:100])
nnet1Pred=results1$net.result
nnet1Rsq = cor(nnet1Pred,valid_norm$target)
nnet1MAPE = mean((nnet1Pred-valid_norm$target)/valid_norm$target)
cat("1 Hidden Unit R-squared:", nnet1Rsq)
cat("1 Hidden Unit MAPE:", nnet1MAPE)
MAE_nnet = sum(abs(results1$net.result - valid_norm$target))/length(valid_norm$target)


#are in our validation data, the MAPE will be undefined. To rescale our predictions to the original measure
#of strength, we need to multiply them by the range of the original variables and add in the minimum
#value. We will then recompute both the R

#(which shouldn’t change since we’re only taking a linear
#transformation of our predictions) and the MAPE for the neural network model.
nnet1PredRescale = nnet1Pred*(max(valid_norm$target)-min(valid_norm$target))+min(valid_norm$target)
nnet1Rsq = cor(nnet1PredRescale,valid_norm$target)
nnet1MAPE = mean((nnet1PredRescale-valid_norm$target)/valid_norm$target)
#nnet1MAE = sum(abs(nnet1PredRescale-train_norm$target))/length(train_norm$target)
cat("1 Hidden Unit R-squared after Rescaling:", nnet1Rsq)
cat("1 Hidden Unit MAPE after Rescaling:", nnet1MAPE)


######################################################################
######################################################################
######################################################################

# Let's try Ridge Regression then...

#' 
#' The glmnet package does not use a model formula but instead requires a design matrix
#' with no intercept column, and a vector containing the target variable. 
#' 
#' This package kindly does all the work of cross-validation for us. We can choose the ridge
#' parameter lambda by trying many different values and seeing which one works best on 
#' cross-validation.

#install.packages("glmnet")
library(glmnet)
set.seed(1)
grid = 10^seq(10,-2,length=100) #' values for lambda you want to try. You can
#' also let the cv.glmnet() function decide on
#' an appropriate interval to test simply by
#' omitting the lambda= option.
train_reg=as.matrix(train)
valid_reg = as.matrix(valid)
cv.out = cv.glmnet(train_reg, train$target, alpha=0, lambda=grid) #' Only using training data
#' for CV!
plot(cv.out)

# Find the value of lambda from cross-validation and see how the resulting model works on the
# test data.

bestlambda=cv.out$lambda.min
bestlambda
(ridge.mod.betas = coef(cv.out, s=bestlambda))
pred.ridge = predict(cv.out, s=bestlambda, newx=valid_reg)
val.MSE.ridge = mean((pred.ridge - valid$target)^2)
val.MSE.ridge

# Final step would be to re-calculate the model on ALL of the data.

out=glmnet(train_reg,train$target,alpha=0, lambda=bestlambda)
ridge.coef = predict(out, type="coefficients")
ridge.coef 

######################################################################
#' Next, let's try LASSO. Again, just optimize the parameter lambda through 
#' Cross-Validation, seeing what provides the lowest MSE.
#' To Run Lasso instead of ridge, simply change alpha to 1.


#' From here, we can grab the best lambda and check the model on our test data.


bestlambda=cv.out$lambda.min
(lasso.mod.betas = coef(cv.out, s=bestlambda))
pred.lasso = predict(cv.out, s=bestlambda, newx=train_reg)
(val.MSE.lasso = mean((pred.lasso-train$target)^2))

#' Results comparable to the other methods. If we want to go with this method,
#' we'd just update the coefficients (by running the entire optimization again)
#' on the entire dataset.

out=glmnet(train_reg,train$target,alpha=1,lambda=bestlambda)
lasso.coef=predict(out, type="coefficients")
lasso.coef

#' Notice the sparsity in the parameter estimates - this is the benefit of LASSO over 
#' Ridge Regression.

# Last thing to try if time permits is the ELASTIC NET
bestlambda=cv.out$lambda.min
(elastic.mod.betas = coef(cv.out, s=bestlambda))
pred.elastic = predict(cv.out, s=bestlambda, newx=train_reg)
(val.MSE.elastic = mean((pred.elastic-train$target)^2))

################################################################################
