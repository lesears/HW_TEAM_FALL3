load('C:\\Users\\escha\\OneDrive\\Documents\\MSA\\Fall Classes\\Clustering\\Data\\final_data.Rdata')

library(readr)
library(glmnet)
library(leaps)
library(factoextra)
library(dplyr)
library(splines)
times <- seq(1,295)/100 # Observations in 1/100th of a second
X <- bs(times,intercept=TRUE,df=60) #create a spline to 
#model the data
betas <- matrix(0,ncol=60,nrow = 6792)
###########################################################
# run a linear regression on each data set
# here I am manipulating my data you I can cluster
###########################################################
for (ii in 1:6792){
  temp <- lm(as.numeric(final_data[ii,6:300])~X-1) #-1 removes the natural intercept
  betas[ii,]  <- coefficients(temp)
}
cdata <- cbind(final_data[,1:5],betas)

#CONVERT EVERTYING TO 'numbers'
cdata$AGE <- as.numeric(cdata$AGE)
cdata$EVER_SMOKE <- as.numeric(cdata$EVER_SMOKE)
cdata$ASTHMA <- as.numeric(cdata$ASTHMA)
cdata$POVERTY_RATIO <- as.numeric(cdata$POVERTY_RATIO)

###################################################################
#######################    Part 1    ##############################
###################################################################

# a) First use principal component analysis to 

pcafinal <- princomp(cdata[,2:65]) #which variables to look into
pcafinal$loadings
pcafinal$center
pcafinal$scores[1,]

pcafinal$sdev
# 1: 45.2117509 , 2: 31.2901007, 3: 22.3753978, 4: 17.3299734, 5: 13.0471355


set.seed(12345)
# Plot this 
fviz_nbclust(pcafinal$scores, kmeans, method = "wss",k.max=20) #4 clusters
fviz_nbclust(pcafinal$scores, kmeans, method = "silhouette",k.max=20) #2 clusters

###################################################################
#######################    Part 2    ##############################
###################################################################
set.seed(12345)
kmean_4 <- kmeans(pcafinal$scores, centers = 4)
cdata$clust <- kmean_4$cluster

# Try to understand the clusters
###################################################################
#
clusters <- list()
for( ii in 1:4){
  clusters[[ii]] <- cdata %>% filter(clust == ii)
}

# Find the means of each cluster to "Name them"
x <- cbind(colMeans(cdata))
y <- x
for (ii in 1:4) {
  x <- cbind(x,colMeans(clusters[[ii]])-y)
}
x

round(x,digits=4)

#view X to determine good names:
# SEQN, Age, Smoke, Asthma, Poverty
#cluster 1=2,3,2,1,1 lowest asthma, lowest poverty
#cluster 2=4,4,1,4,2 highest age, lowest smoking, highest asthma
#cluster 3=3,2,3,2,4 higest poverty
#cluster 4=1,1,4,3,3 lowest age, highest smoking

colMeans(as.data.frame(clusters[4]))

#kmean_4$centers

#plot(kmean_4$centers[,3],ylab="asd",xlab = "asd",
#axes=F,xlim=c(-150,150),ylim=c(-150,150),pch = 16,col="Light Blue",cex=2)
#abline(v=0,lty=2)
#abline(h=0,lty=2)


cmeans <- matrix(colMeans(betas),60,1)
stdev  <- matrix(apply(betas,2,sd),60,1)

set.seed(12345)
k_means4 <- kmeans(scale(betas),4,nstart = 25)

cl1 <- matrix(k_means4$centers[1,],60,1)
bl1 <- cl1 * stdev + cmeans
plot(times,X%*%bl1,ylab="ML",xlab = "Time",type = 'l',lwd=2,col='red',ylim=c(0,100))
cl2 <- matrix(k_means4$centers[2,],60,1)
bl2 <- cl2 * stdev + cmeans
lines(times,X%*%bl2,lwd=2,col='blue')
cl3 <- matrix(k_means4$centers[3,],60,1)
bl3 <- cl3 * stdev + cmeans
lines(times,X%*%bl3,lwd=2,col='green')
cl4 <- matrix(k_means4$centers[4,],60,1)
bl4 <- cl4 * stdev + cmeans
lines(times,X%*%bl4,lwd=2,col='black')


###################################################################
#######################    Part 3    ##############################
###################################################################
set.seed(12345)

library(mclust)
clustBIC <-mclustBIC(cdata[,10:20], modelNames ='VVV', G=1:20)   # This is model selection
plot(clustBIC)

set.seed(12345)

mod1<-mclustBIC(cdata[,10:20], modelNames ='VVV', G=6)
summary(mod1)
mclustF = Mclust(cdata[,10:20], x = mod1)

cdata$newclust <- mclustF$classification

mclusters <- list()
for( ii in 1:6){
  mclusters[[ii]] <- cdata %>% filter(newclust == ii)
}

m <- list()

for (ii in 1:6){
  m[[ii]] <- colMeans(mclusters[[ii]])
}
B <- matrix(m[[1]][6:65],ncol = 1)
plot(times,X%*%B,xlab = "Time",ylab = "ML",type = 'l',col=1,lwd=2,ylim = c(0,100))
B <- matrix(m[[2]][6:65],ncol = 1)
lines(times,X%*%B,col = "red",lwd=2)
B <- matrix(m[[3]][6:65],ncol = 1)
lines(times,X%*%B,col = "green",lwd=2)
B <- matrix(m[[4]][6:65],ncol = 1)
lines(times,X%*%B,col = "blue",lwd=2)
B <- matrix(m[[5]][6:65],ncol = 1)
lines(times,X%*%B,col = "light blue",lwd=2)
B <- matrix(m[[6]][6:65],ncol = 1)
lines(times,X%*%B,col = "purple",lwd=2)

#meancurve <- list()
#for (i in 1:6){
#  meancurve[[i]] <- colMeans(mclusters[[i]][,2:65])
#}

#d <- seq(from = 0, by = (3/64), length.out = 64)
#plot(d,meancurve[[1]],xlab = "Time",ylab = "ML",type = 'l',col=1,lwd=2,ylim = c(0,90))
#lines(d,meancurve[[2]],col=2,lwd=2)#red
#lines(d,meancurve[[3]],col=3,lwd=2)#green
#lines(d,meancurve[[4]],col=4,lwd=2)#blue
#lines(d,meancurve[[5]],col=5,lwd=2)#teal
#lines(d,meancurve[[6]],col=6,lwd=2)#purple



############# Old code? ##################


d <- seq(0,1,0.01)
b <- mclustF$parameters$mean[,1]
p1 <- 1/(1+exp(-b[1]-b[2]*d))
b <- mclustF$parameters$mean[,2]
p2 <- 1/(1+exp(-b[1]-b[2]*d))
b <- mclustF$parameters$mean[,3]
p3 <- 1/(1+exp(-b[1]-b[2]*d))
b <- mclustF$parameters$mean[,4]
p4 <- 1/(1+exp(-b[1]-b[2]*d))
b <- mclustF$parameters$mean[,5]
p5 <- 1/(1+exp(-b[1]-b[2]*d))
b <- mclustF$parameters$mean[,6]
p6 <- 1/(1+exp(-b[1]-b[2]*d))


plot(d,p1,xlab="lung capacity",ylab="Probability",type='l',col = 1,lwd=2,ylim=c(0,1))
lines(d,p2,col=2,lwd=2)
lines(d,p3,col=3,lwd=2)
lines(d,p4,col=4,lwd=2)
lines(d,p5,col=5,lwd=2)
lines(d,p6,col=6,lwd=2)
mclustF$parameters$mean[1,]
