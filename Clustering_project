#To help her in her quest, she wants to look at the differences the reviews for properties that are currently available in Boston.
#She wants to find areas that are of interest to visitors and the qualities of a “good review,” 
#she is interested if there are any areas that seem to have poor reviews in general but are frequently rented due to local tourist attractions. 
#Her goal is to locate areas/properties that are underserved with quality rental sites.

#a.	Renter sentiment towards the property. 
#b.	Location to popular attractions. 
#c.	Average nightly rates per segment (possibly per bed). 
library(readxl)
library(dplyr)
nrc_total <- get_sentiments("afinn")

#######################################################
library(tidytext)
library(stringr)
library(dplyr)
library(text2vec)
library(readr)

reviews = read.csv('C:\\Users\\Laney\\Documents\\Data\\boston-airbnb-open-data\\reviews.csv', header= TRUE)
calendar = read.csv('C:\\Users\\Laney\\Documents\\Data\\boston-airbnb-open-data\\calendar.csv', header= TRUE)
listings = read.csv('C:\\Users\\Laney\\Documents\\Data\\boston-airbnb-open-data\\listings.csv', header=TRUE)

rv <- reviews %>% group_by(listing_id) %>%
  count(listing_id, sort = TRUE) %>% filter( n >= 4) %>% select(-"n")

reviews$comments = as.character(reviews$comments) 
new_reviews <- reviews %>%
  group_by(listing_id) %>%
  unnest_tokens(word, comments)  %>%
  right_join(rv,by="listing_id") %>% filter(!is.na(word)) %>%
  left_join(nrc_total,by="word") %>% filter(!is.na(score))

#Geocode Location
#####################################################
# Need experimental version of ggmap
# also need to download and install rtools off of the internet
library(readr)
library(lubridate)
library(ggplot2)
library(ggmap)
library(dplyr)
library(data.table)
library(ggrepel)

devtools::install_github("dkahle/ggmap", ref = "tidyup")
library(devtools)
#####################################################
#TO DO THIS YOU NEED TO REGISTER TO A GOOGLE DEV ACCOUNT
#AND PROVIDE YOUR OWN API KEY!!!!!
#THEN YOU CAN GET A PRETTY MAP!
# https://www.wpgmaps.com/documentation/creating-a-google-maps-api-key/
# You will also have to get the geocode api enabled
#####################################################

register_google("AIzaSyBnCuXH4BC3sxUhU6TPGX84t5cs7iijPqA")



#########################################
# Get a Map of Boston
#########################################
map <- get_map(location = "Boston", zoom = 12)
map2 <- get_map(location = "Boston", zoom = 11)



#Find the number of words scored
score         <- new_reviews %>% group_by(listing_id) %>% mutate(sscore = sum(score)) %>% distinct(listing_id,sscore)
nwords        <- new_reviews %>% group_by(listing_id) %>% count(listing_id) 

complete <- nwords %>% left_join(score,"listing_id") %>% mutate(avg = sscore/n)
mean(complete$sscore)
hist(complete$sscore, breaks = 30)
hist(complete$avg)



complete$avg <- scale(complete$avg) #standardize the score
colnames(listings)[colnames(listings) == 'id'] <- 'listing_id'
combined <- complete %>% left_join(listings,"listing_id")
combined$std.lat <- scale(combined$latitude)
combined$std.lon <- scale(combined$longitude)
write.csv(combined, 'combined.csv')
a = combined[combined$avg>0,]
b = combined[combined$avg<0,]
c = combined[combined$avg==0,]
hist(a$beds)
hist(b$beds)

a$price = as.numeric(a$price)
hist(a$price, breaks = 10)

b$price = as.numeric(b$price)
hist(b$price, breaks=10)

toC<- cbind(combined$price,combined$std.lat,combined$std.lon)

toC<- cbind(combined$price,combined$std.lat,combined$std.lon)
toC2 = cbind(a$avg, a$std.lat, a$std.lon)
clusters.s2 <- hclust(dist(toC2), method="average")

toC3 = cbind(b$avg, b$std.lat, b$std.lon)
clusters.s3 <- hclust(dist(toC2), method="average")
toC4 = cbind(c$avg, c$std.lat, c$std.lon)

clusters.c <- hclust(dist(toC),method="complete")
clusters.si <- hclust(dist(toC), method="single")
clusters.s <- hclust(dist(toC), method="average")

plot(clusters.s)
combined$clus <- cutree(clusters.s,6) #it looks like 6 clusters is reasonable

library(ggmap)
clu1 <- combined %>% filter(clus == 1)
clu2 <- combined %>% filter(clus == 2)
clu3 <- combined %>% filter(clus == 3)
clu4 <- combined %>% filter(clus == 4)
clu5 <- combined %>% filter(clus == 5)
clu6 <- combined %>% filter(clus == 6)
clu7 <- combined %>% filter(clus == 7)

#I want to find the Geo-location of these listings :-)


#notice U of Washington Right in the middle
ggmap(map, fullpage = TRUE) +
  geom_point(data = a, aes(x = longitude, y = latitude), color = 'red', size = 2)+
  geom_point(data = b, aes(x = longitude, y = latitude), color = 'blue', size = 2)
##postiive and negative sentiment are scattered equally across all areas


###clusters on map ####
ggmap(map, fullpage = TRUE) +
  geom_point(data = clu1, aes(x = longitude, y = latitude), color = 'red', size = 2)+
  geom_point(data = clu2, aes(x = longitude, y = latitude), color = 'blue', size = 2)+
  geom_point(data = clu3, aes(x = longitude, y = latitude), color = 'green', size = 2)+
geom_point(data = clu4, aes(x = longitude, y = latitude), color = 'pink', size = 2)+
  geom_point(data = clu5, aes(x = longitude, y = latitude), color = 'yellow', size = 2)+
  geom_point(data = clu6, aes(x = longitude, y = latitude), color = 'black', size = 2)
  
  #score
hist(clu1$avg)
hist(clu2$avg)
hist(clu3$avg)
  

#beds
  hist(clu1$beds)
  mean(clu1$beds)
  hist(clu2$beds)
  mean(clu2$beds) 
  hist(clu3$beds)
  mean(clu3$beds)  
  hist(clu4$beds)
  mean(clu4$beds)  
  hist(clu5$beds)
  mean(clu5$beds)  
  hist(clu6$beds)
  mean(clu6$beds)
  
   
  #price
  clu1$price = as.numeric(clu1$price)
  hist(clu1$price)
  mean(clu1$beds)
  
  clu2$price = as.numeric(clu2$price)
  hist(clu2$price)
  mean(clu2$beds)
 
  clu3$price = as.numeric(clu3$price)
  hist(clu3$price)
  mean(clu3$beds)
  
  clu4$price = as.numeric(clu4$price)
  hist(clu4$price)
  mean(clu4$beds)
  
  clu5$price = as.numeric(clu5$price)
  hist(clu4$price)
  mean(clu4$beds)
  
  clu6$price = as.numeric(clu6$price)
  hist(clu5$price)
  mean(clu5$beds)

  
  
  
  
  #geom_point(data = clu4, aes(x = longitude, y = latitude), color = 'pink', size = 2)+
  #geom_point(data = clu5, aes(x = longitude, y = latitude), color = 'purple', size = 2)+
  #geom_point(data = clu6, aes(x = longitude, y = latitude), color = 'black', size = 2)+
  #geom_point(data = clu7, aes(x = longitude, y = latitude), color = 'white', size = 2)

###############################
# describe them
###############################

# did as.data.frame because new_reviews
# was made to be a tibble with listing_id being a 'group'
# as.data.frame removes this distinction


words1 <- as.data.frame(new_reviews) %>% right_join(clu1,'listing_id')  %>%
  select(word) %>% count(word,sort=TRUE) %>% filter(n < 150)

words2 <- as.data.frame(new_reviews) %>% right_join(clu2,'listing_id')  %>%
  select(word) %>% count(word,sort=TRUE) %>% filter(n < 150)

words3 <- as.data.frame(new_reviews) %>% right_join(clu3,'listing_id')  %>%
  select(word) %>% count(word,sort=TRUE) %>% filter(n < 150)

words4 <- as.data.frame(new_reviews) %>% right_join(clu4,'listing_id')  %>%
  select(word) %>% count(word,sort=TRUE) %>% filter(n < 150)

words5 <- as.data.frame(new_reviews) %>% right_join(clu5,'listing_id')  %>%
  select(word) %>% count(word,sort=TRUE) %>% filter(n < 150)

words6 <- as.data.frame(new_reviews) %>% right_join(clu6,'listing_id')  %>%
  select(word) %>% count(word,sort=TRUE) %>% filter(n < 150)




#random is not so random
set.seed(555)

wordcloud(words = words1$word_stem, freq = words4$n, min.freq = 150,
          max.words=10, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

set.seed(555)
wordcloud(words = words2$word_stem, freq = words5$n, min.freq = 150,
          max.words=10, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
set.seed(555)
wordcloud(words = words3$word_stem, freq = words3$n, min.freq = 150,
          max.words=10, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
set.seed(555)
wordcloud(words = words4$word, freq = words5$n, min.freq = 150,
          max.words=10, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
set.seed(555)
wordcloud(words = words5$word, freq = words5$n, min.freq = 150,
          max.words=20, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
set.seed(555)
wordcloud(words = words6$word, freq = words5$n, min.freq = 150,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))


